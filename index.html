<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Advanced Audio Analyzer & Mastering</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script>
        tailwind.config = {
            theme: {
                extend: {
                    fontFamily: {
                        inter: ['Inter', 'sans-serif'],
                    },
                    colors: {
                        'neutral-850': '#1c1c1c',
                        'purple-650': '#7c3aed',
                    }
                }
            }
        }
    </script>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap');
        body {
            font-family: 'Inter', sans-serif;
            -webkit-font-smoothing: antialiased;
            -moz-osx-font-smoothing: grayscale;
            background-color: #0d0d0d;
        }
        canvas {
            display: block;
            background-color: #0f0f0f;
            border-radius: 0.75rem;
            box-shadow: inset 0 2px 4px rgba(0,0,0,0.1);
        }
    </style>
</head>
<body class="bg-neutral-950 text-neutral-200 antialiased p-8 flex flex-col items-center justify-center min-h-screen">

    <!-- Main Container -->
    <div class="w-full max-w-4xl bg-neutral-900 rounded-2xl p-8 shadow-2xl space-y-8 border border-neutral-800">

        <!-- Header -->
        <h1 class="text-3xl sm:text-4xl font-bold text-center text-purple-650">Audio Analyzer & Mastering</h1>
        <p class="text-center text-neutral-400 max-w-2xl mx-auto">Upload an audio file to analyze its characteristics and apply real-time mastering effects like a noise gate and limiter.</p>

        <!-- File Input and Controls -->
        <div class="flex flex-col sm:flex-row items-center justify-center space-y-4 sm:space-y-0 sm:space-x-4">
            <label for="audioFile" class="flex-1 w-full sm:w-auto cursor-pointer bg-purple-650 hover:bg-purple-700 text-white font-semibold py-3 px-6 rounded-full transition-colors duration-300 text-center shadow-lg">
                Choose Audio File
            </label>
            <input type="file" id="audioFile" accept="audio/*" class="hidden">
            <button id="playPauseBtn" class="flex-1 w-full sm:w-auto bg-neutral-700 hover:bg-neutral-600 text-white font-semibold py-3 px-6 rounded-full transition-colors duration-300 shadow-lg" disabled>Play / Pause</button>
        </div>

        <!-- Loading Indicator -->
        <div id="loadingIndicator" class="hidden text-center text-purple-400 font-medium">
            <div class="animate-pulse">Loading and analyzing audio...</div>
        </div>

        <!-- Audio Visualization -->
        <div id="visualization-container" class="mt-8">
            <canvas id="spectrogramCanvas" class="w-full h-96"></canvas>
        </div>

        <!-- Mastering & Analysis UI -->
        <div class="grid grid-cols-1 md:grid-cols-2 gap-8 mt-8">

            <!-- Mastering Controls -->
            <div class="bg-neutral-850 p-6 rounded-xl shadow-inner border border-neutral-800">
                <h2 class="text-2xl font-semibold mb-4 text-purple-400">Real-Time Mastering</h2>
                <!-- Noise Gate -->
                <div class="mb-6">
                    <h3 class="text-lg font-medium mb-2 text-neutral-300">Noise Gate</h3>
                    <div class="flex items-center space-x-4 mb-2">
                        <label for="gateThreshold" class="w-24 text-sm text-neutral-400">Threshold:</label>
                        <input type="range" id="gateThreshold" min="-100" max="0" value="-50" step="1" class="w-full h-2 bg-neutral-700 rounded-lg appearance-none cursor-pointer">
                        <span id="gateThresholdValue" class="text-sm font-mono w-12 text-right text-neutral-400">-50 dB</span>
                    </div>
                </div>

                <!-- Limiter -->
                <div>
                    <h3 class="text-lg font-medium mb-2 text-neutral-300">Limiter</h3>
                    <div class="flex items-center space-x-4 mb-2">
                        <label for="limiterThreshold" class="w-24 text-sm text-neutral-400">Threshold:</label>
                        <input type="range" id="limiterThreshold" min="-20" max="0" value="-3" step="0.5" class="w-full h-2 bg-neutral-700 rounded-lg appearance-none cursor-pointer">
                        <span id="limiterThresholdValue" class="text-sm font-mono w-12 text-right text-neutral-400">-3 dB</span>
                    </div>
                </div>
            </div>

            <!-- Analysis Results -->
            <div class="bg-neutral-850 p-6 rounded-xl shadow-inner border border-neutral-800">
                <h2 class="text-2xl font-semibold mb-4 text-purple-400">Analysis Results</h2>
                <div class="flex items-center mb-4">
                    <span class="text-neutral-400 w-24">BPM:</span>
                    <span id="bpmResult" class="text-3xl font-bold text-neutral-100">-</span>
                </div>
                <div class="flex items-center">
                    <span class="text-neutral-400 w-24">Key:</span>
                    <span id="keyResult" class="text-3xl font-bold text-neutral-100">-</span>
                </div>
            </div>
        </div>

        <!-- Message Box -->
        <div id="messageBox" class="hidden mt-8 p-4 bg-red-800 rounded-xl text-red-200 text-center font-semibold"></div>

    </div>

    <script>
        // Use a self-invoking function to avoid global variables
        (function() {
            // --- UI Elements ---
            const audioFile = document.getElementById('audioFile');
            const playPauseBtn = document.getElementById('playPauseBtn');
            const loadingIndicator = document.getElementById('loadingIndicator');
            const spectrogramCanvas = document.getElementById('spectrogramCanvas');
            const gateThreshold = document.getElementById('gateThreshold');
            const gateThresholdValue = document.getElementById('gateThresholdValue');
            const limiterThreshold = document.getElementById('limiterThreshold');
            const limiterThresholdValue = document.getElementById('limiterThresholdValue');
            const bpmResult = document.getElementById('bpmResult');
            const keyResult = document.getElementById('keyResult');
            const messageBox = document.getElementById('messageBox');

            // --- Global State ---
            let audioContext;
            let sourceNode;
            let analyserNode;
            let gateNode;
            let limiterNode;
            let isPlaying = false;
            let audioBuffer;

            // --- Constants for Analysis ---
            const majorKeys = [
                // C Maj
                [6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88],
                // C# Maj
                [2.88, 6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29],
                // ... (add all 12 major and 12 minor templates)
            ];
            const minorKeys = [
                // C Min
                [5.19, 2.39, 3.66, 2.29, 2.88, 6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52],
                // C# Min
                [2.52, 5.19, 2.39, 3.66, 2.29, 2.88, 6.35, 2.23, 3.48, 2.33, 4.38, 4.09]
                // ... (add all 12 major and 12 minor templates)
            ];
            // An array of note names for easy lookup
            const noteNames = ["C", "C#", "D", "D#", "E", "F", "F#", "G", "G#", "A", "A#", "B"];
            const chromaTemplate = [
                // C Major
                [6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88],
                // C Minor
                [5.19, 2.39, 3.66, 2.29, 2.88, 6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52],
                // D Major
                [2.88, 6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29],
                // D Minor
                [2.29, 2.88, 5.19, 2.39, 3.66, 2.29, 2.88, 6.35, 2.23, 3.48, 2.33, 4.38],
                // and so on for all 24 keys...
            ];

            // --- Message Handling ---
            function showMessage(msg, type = 'error') {
                messageBox.textContent = msg;
                messageBox.classList.remove('hidden');
                messageBox.classList.add(type === 'error' ? 'bg-red-800' : 'bg-green-800');
                messageBox.classList.remove(type === 'error' ? 'bg-green-800' : 'bg-red-800');
            }

            function hideMessage() {
                messageBox.classList.add('hidden');
            }

            // --- Core Audio Functions ---

            /**
             * Initializes the audio processing chain: source -> analyser -> gate -> limiter -> destination.
             */
            function initializeAudioChain() {
                // Initialize AudioContext if it doesn't exist
                if (!audioContext) {
                    audioContext = new (window.AudioContext || window.webkitAudioContext)();
                }

                // Create nodes
                sourceNode = audioContext.createBufferSource();
                sourceNode.buffer = audioBuffer;
                
                analyserNode = audioContext.createAnalyser();
                // Set FFT size to a larger value for more accurate frequency analysis
                analyserNode.fftSize = 2048; 

                // Noise Gate Node (uses DynamicsCompressorNode)
                gateNode = audioContext.createDynamicsCompressor();
                gateNode.threshold.setValueAtTime(parseFloat(gateThreshold.value), audioContext.currentTime);
                gateNode.ratio.setValueAtTime(20, audioContext.currentTime); // High ratio for gate
                gateNode.knee.setValueAtTime(0, audioContext.currentTime); // Hard knee
                gateNode.attack.setValueAtTime(0.01, audioContext.currentTime); // Fast attack
                gateNode.release.setValueAtTime(0.1, audioContext.currentTime); // Fast release

                // Limiter Node (also a DynamicsCompressorNode, with infinite ratio)
                limiterNode = audioContext.createDynamicsCompressor();
                limiterNode.threshold.setValueAtTime(parseFloat(limiterThreshold.value), audioContext.currentTime);
                limiterNode.ratio.setValueAtTime(100, audioContext.currentTime); // "Infinite" ratio
                limiterNode.attack.setValueAtTime(0, audioContext.currentTime); // Instant attack
                limiterNode.release.setValueAtTime(0.05, audioContext.currentTime); // Fast release

                // Connect the nodes in the processing chain
                sourceNode.connect(analyserNode);
                analyserNode.connect(gateNode);
                gateNode.connect(limiterNode);
                limiterNode.connect(audioContext.destination);

                // Set up event listener for when the audio finishes
                sourceNode.onended = () => {
                    isPlaying = false;
                    playPauseBtn.textContent = 'Play / Pause';
                };
            }

            /**
             * BPM detection using onset detection and autocorrelation.
             * This is a simplified but more robust algorithm than previous versions.
             * It processes the full audio buffer offline.
             */
            function detectBPM(buffer) {
                const sampleRate = buffer.sampleRate;
                const channelData = buffer.getChannelData(0); // Use one channel
                const hopSize = 512; // Number of samples between analysis frames
                const fftSize = 1024;
                const bufferSize = 2048;

                // Simple onset detection function (ODF) based on energy difference
                const odf = [];
                let prevEnergy = 0;
                for (let i = 0; i < channelData.length - fftSize; i += hopSize) {
                    let energy = 0;
                    for (let j = 0; j < fftSize; j++) {
                        energy += Math.pow(channelData[i + j], 2);
                    }
                    const diff = energy - prevEnergy;
                    odf.push(diff > 0 ? diff : 0);
                    prevEnergy = energy;
                }
                
                // Autocorrelation to find repeating patterns (BPM)
                const ac = new Array(odf.length).fill(0);
                for (let tau = 0; tau < odf.length; tau++) {
                    for (let i = 0; i < odf.length - tau; i++) {
                        ac[tau] += odf[i] * odf[i + tau];
                    }
                }

                // Find the peak in the autocorrelation that corresponds to a reasonable BPM range
                const minLag = Math.floor(sampleRate / (300 / 60)); // 300 BPM
                const maxLag = Math.floor(sampleRate / (40 / 60));  // 40 BPM
                let maxCorrelation = 0;
                let bestLag = 0;

                for (let i = minLag; i < maxLag; i++) {
                    if (ac[i] > maxCorrelation) {
                        maxCorrelation = ac[i];
                        bestLag = i;
                    }
                }

                if (bestLag === 0) {
                    return 0;
                }

                // Calculate BPM from the best lag
                const bpm = 60 / ((bestLag * hopSize) / sampleRate);
                return Math.round(bpm);
            }

            /**
             * Key detection using chromagram and key templates.
             * Processes the full audio buffer offline.
             */
            function detectKey(buffer) {
                const sampleRate = buffer.sampleRate;
                const channelData = buffer.getChannelData(0);
                const fftSize = 4096;
                const hopSize = 2048;
                let chromaVector = new Array(12).fill(0);
                let totalFrames = 0;

                // Process audio in chunks
                for (let i = 0; i < channelData.length - fftSize; i += hopSize) {
                    const frame = channelData.slice(i, i + fftSize);
                    
                    // Simple FFT calculation (for demonstration, a full FFT library would be more accurate)
                    // We'll simulate pitch class profiles by summing energy in frequency bins.
                    const frameChroma = new Array(12).fill(0);
                    
                    // This is a simplified and rough approximation. A real-world app would use a
                    // dedicated FFT library and more complex pitch detection algorithms.
                    const minFreq = 60; // C2
                    const maxFreq = 6000;
                    
                    for (let j = 0; j < frame.length; j++) {
                        const freq = j * sampleRate / fftSize;
                        if (freq > minFreq && freq < maxFreq) {
                            const noteIndex = Math.round(12 * (Math.log2(freq / 440)) + 9) % 12;
                            if (noteIndex >= 0) {
                                frameChroma[noteIndex] += Math.abs(frame[j]);
                            }
                        }
                    }

                    // Normalize and add to total chroma vector
                    const sum = frameChroma.reduce((a, b) => a + b, 0);
                    if (sum > 0) {
                        for (let j = 0; j < 12; j++) {
                            chromaVector[j] += frameChroma[j] / sum;
                        }
                        totalFrames++;
                    }
                }
                
                if (totalFrames > 0) {
                    chromaVector = chromaVector.map(val => val / totalFrames);
                } else {
                    return "N/A";
                }

                // Correlate with key templates
                let maxCorrelation = -1;
                let bestKey = "N/A";

                for (let i = 0; i < 24; i++) {
                    const template = chromaTemplate[i];
                    let correlation = 0;
                    for (let j = 0; j < 12; j++) {
                        correlation += chromaVector[j] * template[j];
                    }
                    if (correlation > maxCorrelation) {
                        maxCorrelation = correlation;
                        const note = noteNames[i % 12];
                        const type = i < 12 ? 'Major' : 'Minor';
                        bestKey = `${note} ${type}`;
                    }
                }

                return bestKey;
            }

            /**
             * Draws the spectrogram visualization on the canvas.
             */
            function drawSpectrogram() {
                const canvasCtx = spectrogramCanvas.getContext('2d');
                const WIDTH = spectrogramCanvas.width;
                const HEIGHT = spectrogramCanvas.height;

                analyserNode.fftSize = 2048; // Set the size for visualization
                const bufferLength = analyserNode.frequencyBinCount;
                const dataArray = new Uint8Array(bufferLength);

                function draw() {
                    requestAnimationFrame(draw);
                    analyserNode.getByteFrequencyData(dataArray);

                    // Create gradient for better visuals
                    const gradient = canvasCtx.createLinearGradient(0, 0, 0, HEIGHT);
                    gradient.addColorStop(0, 'rgba(124, 58, 237, 0.8)'); // Purple
                    gradient.addColorStop(0.5, 'rgba(124, 58, 237, 0.4)');
                    gradient.addColorStop(1, 'rgba(255, 255, 255, 0)');

                    canvasCtx.fillStyle = '#0f0f0f';
                    canvasCtx.fillRect(0, 0, WIDTH, HEIGHT);
                    canvasCtx.fillStyle = gradient;

                    const barWidth = (WIDTH / bufferLength) * 2.5;
                    let barHeight;
                    let x = 0;

                    for (let i = 0; i < bufferLength; i++) {
                        barHeight = dataArray[i];
                        canvasCtx.fillRect(x, HEIGHT - barHeight, barWidth, barHeight);
                        x += barWidth + 1;
                    }
                };
                draw();
            }

            // --- Event Listeners ---

            // File input handler
            audioFile.addEventListener('change', async (event) => {
                const file = event.target.files[0];
                if (!file) return;

                hideMessage();
                loadingIndicator.classList.remove('hidden');
                playPauseBtn.disabled = true;

                try {
                    const arrayBuffer = await file.arrayBuffer();
                    if (!audioContext) {
                        audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    }
                    audioBuffer = await audioContext.decodeAudioData(arrayBuffer);

                    // Run offline analysis
                    const bpm = detectBPM(audioBuffer);
                    const key = detectKey(audioBuffer);
                    bpmResult.textContent = `${bpm}`;
                    keyResult.textContent = key;
                    
                    initializeAudioChain();
                    playPauseBtn.disabled = false;
                    loadingIndicator.classList.add('hidden');
                    showMessage("Audio loaded and analyzed successfully!", 'success');
                    
                    // Automatically start playing on file load
                    sourceNode.start(0);
                    isPlaying = true;
                    playPauseBtn.textContent = 'Pause';
                    drawSpectrogram();

                } catch (e) {
                    console.error('Error decoding audio:', e);
                    showMessage('Error decoding audio. Please try a different file.');
                    playPauseBtn.disabled = true;
                    loadingIndicator.classList.add('hidden');
                }
            });

            // Play/Pause button handler
            playPauseBtn.addEventListener('click', () => {
                if (audioContext.state === 'suspended') {
                    audioContext.resume();
                    isPlaying = true;
                    playPauseBtn.textContent = 'Pause';
                } else if (audioContext.state === 'running') {
                    audioContext.suspend();
                    isPlaying = false;
                    playPauseBtn.textContent = 'Play';
                }
            });

            // Mastering control listeners
            gateThreshold.addEventListener('input', (e) => {
                const value = parseFloat(e.target.value);
                gateThresholdValue.textContent = `${value} dB`;
                if (gateNode) {
                    gateNode.threshold.setValueAtTime(value, audioContext.currentTime);
                }
            });

            limiterThreshold.addEventListener('input', (e) => {
                const value = parseFloat(e.target.value);
                limiterThresholdValue.textContent = `${value} dB`;
                if (limiterNode) {
                    limiterNode.threshold.setValueAtTime(value, audioContext.currentTime);
                }
            });

            // Initial UI setup on page load
            window.addEventListener('load', () => {
                // Initial values for sliders
                gateThresholdValue.textContent = `${gateThreshold.value} dB`;
                limiterThresholdValue.textContent = `${limiterThreshold.value} dB`;

                // Set canvas size for responsiveness
                const container = document.getElementById('visualization-container');
                const resizeObserver = new ResizeObserver(entries => {
                    for (let entry of entries) {
                        const { width, height } = entry.contentRect;
                        spectrogramCanvas.width = width;
                        spectrogramCanvas.height = height;
                    }
                });
                resizeObserver.observe(container);
            });
        })();
    </script>
</body>
</html>
